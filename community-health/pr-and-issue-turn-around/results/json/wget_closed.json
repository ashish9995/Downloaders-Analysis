[{
		"url": "https://api.github.com/repos/mirror/wget/issues/4",
		"repository_url": "https://api.github.com/repos/mirror/wget",
		"labels_url": "https://api.github.com/repos/mirror/wget/issues/4/labels{/name}",
		"comments_url": "https://api.github.com/repos/mirror/wget/issues/4/comments",
		"events_url": "https://api.github.com/repos/mirror/wget/issues/4/events",
		"html_url": "https://github.com/mirror/wget/pull/4",
		"id": 220190932,
		"node_id": "MDExOlB1bGxSZXF1ZXN0MTE0Nzk5MzEw",
		"number": 4,
		"title": "Test pull request",
		"user": {
			"login": "hubertta",
			"id": 6797437,
			"node_id": "MDQ6VXNlcjY3OTc0Mzc=",
			"avatar_url": "https://avatars2.githubusercontent.com/u/6797437?v=4",
			"gravatar_id": "",
			"url": "https://api.github.com/users/hubertta",
			"html_url": "https://github.com/hubertta",
			"followers_url": "https://api.github.com/users/hubertta/followers",
			"following_url": "https://api.github.com/users/hubertta/following{/other_user}",
			"gists_url": "https://api.github.com/users/hubertta/gists{/gist_id}",
			"starred_url": "https://api.github.com/users/hubertta/starred{/owner}{/repo}",
			"subscriptions_url": "https://api.github.com/users/hubertta/subscriptions",
			"organizations_url": "https://api.github.com/users/hubertta/orgs",
			"repos_url": "https://api.github.com/users/hubertta/repos",
			"events_url": "https://api.github.com/users/hubertta/events{/privacy}",
			"received_events_url": "https://api.github.com/users/hubertta/received_events",
			"type": "User",
			"site_admin": false
		},
		"labels": [],
		"state": "closed",
		"locked": false,
		"assignee": null,
		"assignees": [],
		"milestone": null,
		"comments": 0,
		"created_at": "2017-04-07T11:46:20Z",
		"updated_at": "2017-04-07T11:50:28Z",
		"closed_at": "2017-04-07T11:50:28Z",
		"author_association": "CONTRIBUTOR",
		"pull_request": {
			"url": "https://api.github.com/repos/mirror/wget/pulls/4",
			"html_url": "https://github.com/mirror/wget/pull/4",
			"diff_url": "https://github.com/mirror/wget/pull/4.diff",
			"patch_url": "https://github.com/mirror/wget/pull/4.patch"
		},
		"body": ""
	}, {
		"url": "https://api.github.com/repos/mirror/wget/issues/3",
		"repository_url": "https://api.github.com/repos/mirror/wget",
		"labels_url": "https://api.github.com/repos/mirror/wget/issues/3/labels{/name}",
		"comments_url": "https://api.github.com/repos/mirror/wget/issues/3/comments",
		"events_url": "https://api.github.com/repos/mirror/wget/issues/3/events",
		"html_url": "https://github.com/mirror/wget/issues/3",
		"id": 208165579,
		"node_id": "MDU6SXNzdWUyMDgxNjU1Nzk=",
		"number": 3,
		"title": "\"sed -i\" in bootstrap.conf is not platform-neutral",
		"user": {
			"login": "vollkommenheit",
			"id": 19334495,
			"node_id": "MDQ6VXNlcjE5MzM0NDk1",
			"avatar_url": "https://avatars1.githubusercontent.com/u/19334495?v=4",
			"gravatar_id": "",
			"url": "https://api.github.com/users/vollkommenheit",
			"html_url": "https://github.com/vollkommenheit",
			"followers_url": "https://api.github.com/users/vollkommenheit/followers",
			"following_url": "https://api.github.com/users/vollkommenheit/following{/other_user}",
			"gists_url": "https://api.github.com/users/vollkommenheit/gists{/gist_id}",
			"starred_url": "https://api.github.com/users/vollkommenheit/starred{/owner}{/repo}",
			"subscriptions_url": "https://api.github.com/users/vollkommenheit/subscriptions",
			"organizations_url": "https://api.github.com/users/vollkommenheit/orgs",
			"repos_url": "https://api.github.com/users/vollkommenheit/repos",
			"events_url": "https://api.github.com/users/vollkommenheit/events{/privacy}",
			"received_events_url": "https://api.github.com/users/vollkommenheit/received_events",
			"type": "User",
			"site_admin": false
		},
		"labels": [],
		"state": "closed",
		"locked": false,
		"assignee": null,
		"assignees": [],
		"milestone": null,
		"comments": 0,
		"created_at": "2017-02-16T16:04:51Z",
		"updated_at": "2017-04-19T14:10:44Z",
		"closed_at": "2017-04-19T14:10:44Z",
		"author_association": "NONE",
		"body": "Commit 32e26dc199be48803db4c695c78b9c4843f179f1 causes bootstrap to fail on OS X with:\r\n\r\n  - invoke gl_INIT in ./configure.ac.\r\nCreating lib/unicase/special-casing-table.h for gperf < 3.1\r\nsed: 1: \"lib/unicase/special-cas ...\": extra characters at the end of l command\r\n./bootstrap: bootstrap_post_import_hook failed\r\n\r\nPer the discussion at\r\nhttps://stackoverflow.com/questions/5694228/sed-in-place-flag-that-works-both-on-mac-bsd-and-linux, the -i option is not part of POSIX Sed, and is apparently implemented differently on BSD/Apple OS X/macOS."
	}, {
		"url": "https://api.github.com/repos/mirror/wget/issues/1",
		"repository_url": "https://api.github.com/repos/mirror/wget",
		"labels_url": "https://api.github.com/repos/mirror/wget/issues/1/labels{/name}",
		"comments_url": "https://api.github.com/repos/mirror/wget/issues/1/comments",
		"events_url": "https://api.github.com/repos/mirror/wget/issues/1/events",
		"html_url": "https://github.com/mirror/wget/pull/1",
		"id": 14013043,
		"node_id": "MDExOlB1bGxSZXF1ZXN0NTU1MDg2NA==",
		"number": 1,
		"title": "Add LIFO queue option for recursive download",
		"user": {
			"login": "john-peterson",
			"id": 207571,
			"node_id": "MDQ6VXNlcjIwNzU3MQ==",
			"avatar_url": "https://avatars0.githubusercontent.com/u/207571?v=4",
			"gravatar_id": "",
			"url": "https://api.github.com/users/john-peterson",
			"html_url": "https://github.com/john-peterson",
			"followers_url": "https://api.github.com/users/john-peterson/followers",
			"following_url": "https://api.github.com/users/john-peterson/following{/other_user}",
			"gists_url": "https://api.github.com/users/john-peterson/gists{/gist_id}",
			"starred_url": "https://api.github.com/users/john-peterson/starred{/owner}{/repo}",
			"subscriptions_url": "https://api.github.com/users/john-peterson/subscriptions",
			"organizations_url": "https://api.github.com/users/john-peterson/orgs",
			"repos_url": "https://api.github.com/users/john-peterson/repos",
			"events_url": "https://api.github.com/users/john-peterson/events{/privacy}",
			"received_events_url": "https://api.github.com/users/john-peterson/received_events",
			"type": "User",
			"site_admin": false
		},
		"labels": [{
				"id": 38649432,
				"node_id": "MDU6TGFiZWwzODY0OTQzMg==",
				"url": "https://api.github.com/repos/mirror/wget/labels/enhancement",
				"name": "enhancement",
				"color": "84b6eb",
				"default": true
			}
		],
		"state": "closed",
		"locked": false,
		"assignee": null,
		"assignees": [],
		"milestone": null,
		"comments": 10,
		"created_at": "2013-05-06T18:04:39Z",
		"updated_at": "2015-01-30T12:10:30Z",
		"closed_at": "2015-01-06T19:57:13Z",
		"author_association": "MEMBER",
		"pull_request": {
			"url": "https://api.github.com/repos/mirror/wget/pulls/1",
			"html_url": "https://github.com/mirror/wget/pull/1",
			"diff_url": "https://github.com/mirror/wget/pull/1.diff",
			"patch_url": "https://github.com/mirror/wget/pull/1.patch"
		},
		"body": "## basic problem\n\nthe basic problem is that the FIFO queue can create a long time between downloading a page and its links. this is different from the browser experience that the page is designed for. resulting in wget fail that a browser user dont experience\n## savannah link\n\nthis patch is also posted at https://savannah.gnu.org/bugs/?37581\n## making it optional\n\n> To get your patch into git please add a command-line option to activate LIFO behavior. \n\nk the patch is changed here https://github.com/mirror/wget/pull/1\n\nthe patch file is https://github.com/mirror/wget/pull/1.patch\n## reason to place html pages at the top of the queue\n\nif ll_bubblesort isn't used only the deepest level links are downloaded directly after its parent page despite using LIFO\n## alternative solution\n### enqueue child directly after parent seem difficult\n\nanother solution is to enqueue the depth n+1 links directly after enqueuing its parent depth n link instead of continuing enqueuing depth n links\n\nthis require interrupting the depth n enqueue at html links. dequeue everything (including the html link). enqueue the depth n+1 links. and the continue the depth n enqueue. this require a big reorganization or doesnt make sense\n\na way to do this could be to store the non-enqueued links in a temporary queue and enqueue them after everything else\n\nthe LIFO solution is better than this solution bc\n- it's simpler code\n- the only benefit is small: that it would download html pages from top to bottom instead of in an arbitrary order (sort place html pages on top of the queue in an arbitrary order)\n### enqueue html last doesnt work\n\nkeeping FIFO and enqueue html links last (with sort) doesnt solve the problem because all depth n links are still downloaded before any depth n+1 links\n## test case description\n\n> I am not sure why you expect that all the resources from 60 \"branches\" can be downloaded in less than 60s when the \"branches\" itself can't.\n\ni dont mean that all resources can be downloaded fast. i just mean that they are downloaded directly after the page that contain them\n\nthe example is an image hosting site (imagevenue.com) where all images has its own html page (imagevenue.com/img.php) with a generated image link that expires a while after the html page is generated to prevent links directly to image files\n\nall links can be downloaded with lifo because each branch page has only 1 link in this example and there's more than enough time to download that 1 link if the download begin directly after the link is generated\n\nif a branch page (f.e. imagevenue.com/img.php) had many images (links) there could still be a problem. but the problem would be the same for regular users (browsers) that download the resource directly after the page is loaded and the fault is therefore the site's rather than wget's\n## test\n### imagevenue fail\n\nthis fails to download the imagevenue.com/img.php images because it's downloading all the img.php pages before the temporary image links in them, and by the time it gets to them they're expired\n\n```\nwget -rHpE -l1 -t2 -T10 -np -nc -nH -nd -e robots=off -D'imagevenue.com' -R'th_*.jpg,th_*.JPG,.gif,.png,.css,.js' http://forum.glam0ur.com/hot-babe-galleries/11956-merilyn-sekova-aka-busty-merilyn.html\n```\n\nthis downloads images directly after a img.php page is downloaded so they dont have time to expire\n\n```\nwget -rHpE -l1 -t2 -T10 -np -nc -nH -nd --queue-type=lifo -e robots=off -D'imagevenue.com' -R'th_*.jpg,th_*.JPG,.gif,.png,.css,.js' http://forum.glam0ur.com/hot-babe-galleries/11956-merilyn-sekova-aka-busty-merilyn.html\n```\n### invalid input\n\ninvalid input is prevented\n\n```\nwget --queue-type=fiffo\n\nwget: --queue-type: Invalid value ‘fiffo’.\n```\n### download order\n\nthis test show the FIFO and LIFO download order\n\ni created this local site:\n\n```\n$ tree\n.\n├── a\n│   ├── a\n│   │   ├── a-a-x.jpg\n│   │   ├── a-a-y.jpg\n│   │   └── a-a.html\n│   ├── a-x.jpg\n│   ├── a-y.jpg\n│   ├── a.html\n│   └── b\n│       ├── a-b-x.jpg\n│       ├── a-b-y.jpg\n│       └── a-b.html\n├── b\n│   ├── a\n│   │   ├── b-a-x.jpg\n│   │   ├── b-a-y.jpg\n│   │   └── b-a.html\n│   ├── b\n│   │   ├── b-b-x.jpg\n│   │   ├── b-b-y.jpg\n│   │   └── b-b.html\n│   ├── b-x.jpg\n│   ├── b-y.jpg\n│   └── b.html\n├── i.html\n├── x.jpg\n└── y.jpg\n\n6 directories, 21 files\n```\n\ni.html\n\n```\n<a href=\"a/a.html\"><img src=\"x.jpg\"></a>\n<a href=\"b/b.html\"><img src=\"y.jpg\"></a>\n```\n\na.html\n\n```\n<a href=\"a/a-a.html\"><img src=\"a-x.jpg\"></a>\n<a href=\"b/a-b.html\"><img src=\"a-y.jpg\"></a>\n```\n\na-a.html\n\n```\n<img src=\"a-a-x.jpg\">\n<img src=\"a-a-y.jpg\">\n```\n\na-b.html\n\n```\n<img src=\"a-b-x.jpg\">\n<img src=\"a-b-y.jpg\">\n```\n\nb.html\n\n```\n<a href=\"a/b-a.html\"><img src=\"b-x.jpg\"></a>\n<a href=\"b/b-b.html\"><img src=\"b-y.jpg\"></a>\n```\n\nb-a.html\n\n```\n<img src=\"b-a-x.jpg\">\n<img src=\"b-a-y.jpg\">\n```\n\nb-b.html\n\n```\n<img src=\"b-b-x.jpg\">\n<img src=\"b-b-y.jpg\">\n```\n\nfifo download links long after its parent page. especially the deepest level links\n\n```\nwget -vdrp -nd http://localhost/code/html/test/download/i.html 2>&1 | egrep \"^Enqueuing|Dequeuing|Saving to\"\n\nEnqueuing http://localhost/code/html/test/download/i.html at depth 0\nDequeuing http://localhost/code/html/test/download/i.html at depth 0\nSaving to: ‘i.html’\nEnqueuing http://localhost/code/html/test/download/a/a.html at depth 1\nEnqueuing http://localhost/code/html/test/download/x.jpg at depth 1\nEnqueuing http://localhost/code/html/test/download/b/b.html at depth 1\nEnqueuing http://localhost/code/html/test/download/y.jpg at depth 1\nDequeuing http://localhost/code/html/test/download/a/a.html at depth 1\nSaving to: ‘a.html’\nEnqueuing http://localhost/code/html/test/download/a/a/a-a.html at depth 2\nEnqueuing http://localhost/code/html/test/download/a/a-x.jpg at depth 2\nEnqueuing http://localhost/code/html/test/download/a/b/a-b.html at depth 2\nEnqueuing http://localhost/code/html/test/download/a/a-y.jpg at depth 2\nDequeuing http://localhost/code/html/test/download/x.jpg at depth 1\nSaving to: ‘x.jpg’\nDequeuing http://localhost/code/html/test/download/b/b.html at depth 1\nSaving to: ‘b.html’\nEnqueuing http://localhost/code/html/test/download/b/a/b-a.html at depth 2\nEnqueuing http://localhost/code/html/test/download/b/b-x.jpg at depth 2\nEnqueuing http://localhost/code/html/test/download/b/b/b-b.html at depth 2\nEnqueuing http://localhost/code/html/test/download/b/b-y.jpg at depth 2\nDequeuing http://localhost/code/html/test/download/y.jpg at depth 1\nSaving to: ‘y.jpg’\nDequeuing http://localhost/code/html/test/download/a/a/a-a.html at depth 2\nSaving to: ‘a-a.html’\nEnqueuing http://localhost/code/html/test/download/a/a/a-a-x.jpg at depth 3\nEnqueuing http://localhost/code/html/test/download/a/a/a-a-y.jpg at depth 3\nDequeuing http://localhost/code/html/test/download/a/a-x.jpg at depth 2\nSaving to: ‘a-x.jpg’\nDequeuing http://localhost/code/html/test/download/a/b/a-b.html at depth 2\nSaving to: ‘a-b.html’\nEnqueuing http://localhost/code/html/test/download/a/b/a-b-x.jpg at depth 3\nEnqueuing http://localhost/code/html/test/download/a/b/a-b-y.jpg at depth 3\nDequeuing http://localhost/code/html/test/download/a/a-y.jpg at depth 2\nSaving to: ‘a-y.jpg’\nDequeuing http://localhost/code/html/test/download/b/a/b-a.html at depth 2\nSaving to: ‘b-a.html’\nEnqueuing http://localhost/code/html/test/download/b/a/b-a-x.jpg at depth 3\nEnqueuing http://localhost/code/html/test/download/b/a/b-a-y.jpg at depth 3\nDequeuing http://localhost/code/html/test/download/b/b-x.jpg at depth 2\nSaving to: ‘b-x.jpg’\nDequeuing http://localhost/code/html/test/download/b/b/b-b.html at depth 2\nSaving to: ‘b-b.html’\nEnqueuing http://localhost/code/html/test/download/b/b/b-b-x.jpg at depth 3\nEnqueuing http://localhost/code/html/test/download/b/b/b-b-y.jpg at depth 3\nDequeuing http://localhost/code/html/test/download/b/b-y.jpg at depth 2\nSaving to: ‘b-y.jpg’\nDequeuing http://localhost/code/html/test/download/a/a/a-a-x.jpg at depth 3\nSaving to: ‘a-a-x.jpg’\nDequeuing http://localhost/code/html/test/download/a/a/a-a-y.jpg at depth 3\nSaving to: ‘a-a-y.jpg’\nDequeuing http://localhost/code/html/test/download/a/b/a-b-x.jpg at depth 3\nSaving to: ‘a-b-x.jpg’\nDequeuing http://localhost/code/html/test/download/a/b/a-b-y.jpg at depth 3\nSaving to: ‘a-b-y.jpg’\nDequeuing http://localhost/code/html/test/download/b/a/b-a-x.jpg at depth 3\nSaving to: ‘b-a-x.jpg’\nDequeuing http://localhost/code/html/test/download/b/a/b-a-y.jpg at depth 3\nSaving to: ‘b-a-y.jpg’\nDequeuing http://localhost/code/html/test/download/b/b/b-b-x.jpg at depth 3\nSaving to: ‘b-b-x.jpg’\nDequeuing http://localhost/code/html/test/download/b/b/b-b-y.jpg at depth 3\nSaving to: ‘b-b-y.jpg’\n```\n\nlifo download links directly after its parent page\n\n```\nwget -vdrp -nd --queue-type=lifo http://localhost/code/html/test/download/i.html 2>&1 | egrep \"^Enqueuing|Dequeuing|Saving to\"\n\nEnqueuing http://localhost/code/html/test/download/i.html at depth 0\nDequeuing http://localhost/code/html/test/download/i.html at depth 0\nSaving to: ‘i.html’\nEnqueuing http://localhost/code/html/test/download/a/a.html at depth 1\nEnqueuing http://localhost/code/html/test/download/b/b.html at depth 1\nEnqueuing http://localhost/code/html/test/download/x.jpg at depth 1\nEnqueuing http://localhost/code/html/test/download/y.jpg at depth 1\nDequeuing http://localhost/code/html/test/download/y.jpg at depth 1\nSaving to: ‘y.jpg’\nDequeuing http://localhost/code/html/test/download/x.jpg at depth 1\nSaving to: ‘x.jpg’\nDequeuing http://localhost/code/html/test/download/b/b.html at depth 1\nSaving to: ‘b.html’\nEnqueuing http://localhost/code/html/test/download/b/a/b-a.html at depth 2\nEnqueuing http://localhost/code/html/test/download/b/b/b-b.html at depth 2\nEnqueuing http://localhost/code/html/test/download/b/b-x.jpg at depth 2\nEnqueuing http://localhost/code/html/test/download/b/b-y.jpg at depth 2\nDequeuing http://localhost/code/html/test/download/b/b-y.jpg at depth 2\nSaving to: ‘b-y.jpg’\nDequeuing http://localhost/code/html/test/download/b/b-x.jpg at depth 2\nSaving to: ‘b-x.jpg’\nDequeuing http://localhost/code/html/test/download/b/b/b-b.html at depth 2\nSaving to: ‘b-b.html’\nEnqueuing http://localhost/code/html/test/download/b/b/b-b-x.jpg at depth 3\nEnqueuing http://localhost/code/html/test/download/b/b/b-b-y.jpg at depth 3\nDequeuing http://localhost/code/html/test/download/b/b/b-b-y.jpg at depth 3\nSaving to: ‘b-b-y.jpg’\nDequeuing http://localhost/code/html/test/download/b/b/b-b-x.jpg at depth 3\nSaving to: ‘b-b-x.jpg’\nDequeuing http://localhost/code/html/test/download/b/a/b-a.html at depth 2\nSaving to: ‘b-a.html’\nEnqueuing http://localhost/code/html/test/download/b/a/b-a-x.jpg at depth 3\nEnqueuing http://localhost/code/html/test/download/b/a/b-a-y.jpg at depth 3\nDequeuing http://localhost/code/html/test/download/b/a/b-a-y.jpg at depth 3\nSaving to: ‘b-a-y.jpg’\nDequeuing http://localhost/code/html/test/download/b/a/b-a-x.jpg at depth 3\nSaving to: ‘b-a-x.jpg’\nDequeuing http://localhost/code/html/test/download/a/a.html at depth 1\nSaving to: ‘a.html’\nEnqueuing http://localhost/code/html/test/download/a/a/a-a.html at depth 2\nEnqueuing http://localhost/code/html/test/download/a/b/a-b.html at depth 2\nEnqueuing http://localhost/code/html/test/download/a/a-x.jpg at depth 2\nEnqueuing http://localhost/code/html/test/download/a/a-y.jpg at depth 2\nDequeuing http://localhost/code/html/test/download/a/a-y.jpg at depth 2\nSaving to: ‘a-y.jpg’\nDequeuing http://localhost/code/html/test/download/a/a-x.jpg at depth 2\nSaving to: ‘a-x.jpg’\nDequeuing http://localhost/code/html/test/download/a/b/a-b.html at depth 2\nSaving to: ‘a-b.html’\nEnqueuing http://localhost/code/html/test/download/a/b/a-b-x.jpg at depth 3\nEnqueuing http://localhost/code/html/test/download/a/b/a-b-y.jpg at depth 3\nDequeuing http://localhost/code/html/test/download/a/b/a-b-y.jpg at depth 3\nSaving to: ‘a-b-y.jpg’\nDequeuing http://localhost/code/html/test/download/a/b/a-b-x.jpg at depth 3\nSaving to: ‘a-b-x.jpg’\nDequeuing http://localhost/code/html/test/download/a/a/a-a.html at depth 2\nSaving to: ‘a-a.html’\nEnqueuing http://localhost/code/html/test/download/a/a/a-a-x.jpg at depth 3\nEnqueuing http://localhost/code/html/test/download/a/a/a-a-y.jpg at depth 3\nDequeuing http://localhost/code/html/test/download/a/a/a-a-y.jpg at depth 3\nSaving to: ‘a-a-y.jpg’\nDequeuing http://localhost/code/html/test/download/a/a/a-a-x.jpg at depth 3\nSaving to: ‘a-a-x.jpg’\n```\n"
	}
]
